{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name : Aishwarya Donegiri\n",
    "# USC ID : 4640782493"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (a) Vetebral Column Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pelvic Incidence</th>\n",
       "      <th>Pelvic Tilt</th>\n",
       "      <th>Lumbar Lordosis Angle</th>\n",
       "      <th>Sacral Slope</th>\n",
       "      <th>Pelvic Radius</th>\n",
       "      <th>Grade of Spondylolisthesis</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.03</td>\n",
       "      <td>22.55</td>\n",
       "      <td>39.61</td>\n",
       "      <td>40.48</td>\n",
       "      <td>98.67</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.06</td>\n",
       "      <td>10.06</td>\n",
       "      <td>25.02</td>\n",
       "      <td>29.00</td>\n",
       "      <td>114.41</td>\n",
       "      <td>4.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.83</td>\n",
       "      <td>22.22</td>\n",
       "      <td>50.09</td>\n",
       "      <td>46.61</td>\n",
       "      <td>105.99</td>\n",
       "      <td>-3.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.30</td>\n",
       "      <td>24.65</td>\n",
       "      <td>44.31</td>\n",
       "      <td>44.64</td>\n",
       "      <td>101.87</td>\n",
       "      <td>11.21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.71</td>\n",
       "      <td>9.65</td>\n",
       "      <td>28.32</td>\n",
       "      <td>40.06</td>\n",
       "      <td>108.17</td>\n",
       "      <td>7.92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>47.90</td>\n",
       "      <td>13.62</td>\n",
       "      <td>36.00</td>\n",
       "      <td>34.29</td>\n",
       "      <td>117.45</td>\n",
       "      <td>-4.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>53.94</td>\n",
       "      <td>20.72</td>\n",
       "      <td>29.22</td>\n",
       "      <td>33.22</td>\n",
       "      <td>114.37</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>61.45</td>\n",
       "      <td>22.69</td>\n",
       "      <td>46.17</td>\n",
       "      <td>38.75</td>\n",
       "      <td>125.67</td>\n",
       "      <td>-2.71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>45.25</td>\n",
       "      <td>8.69</td>\n",
       "      <td>41.58</td>\n",
       "      <td>36.56</td>\n",
       "      <td>118.55</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>33.84</td>\n",
       "      <td>5.07</td>\n",
       "      <td>36.64</td>\n",
       "      <td>28.77</td>\n",
       "      <td>123.95</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pelvic Incidence  Pelvic Tilt  Lumbar Lordosis Angle  Sacral Slope  \\\n",
       "0               63.03        22.55                  39.61         40.48   \n",
       "1               39.06        10.06                  25.02         29.00   \n",
       "2               68.83        22.22                  50.09         46.61   \n",
       "3               69.30        24.65                  44.31         44.64   \n",
       "4               49.71         9.65                  28.32         40.06   \n",
       "..                ...          ...                    ...           ...   \n",
       "305             47.90        13.62                  36.00         34.29   \n",
       "306             53.94        20.72                  29.22         33.22   \n",
       "307             61.45        22.69                  46.17         38.75   \n",
       "308             45.25         8.69                  41.58         36.56   \n",
       "309             33.84         5.07                  36.64         28.77   \n",
       "\n",
       "     Pelvic Radius  Grade of Spondylolisthesis  Class  \n",
       "0            98.67                       -0.25      1  \n",
       "1           114.41                        4.56      1  \n",
       "2           105.99                       -3.53      1  \n",
       "3           101.87                       11.21      1  \n",
       "4           108.17                        7.92      1  \n",
       "..             ...                         ...    ...  \n",
       "305         117.45                       -4.25      0  \n",
       "306         114.37                       -0.42      0  \n",
       "307         125.67                       -2.71      0  \n",
       "308         118.55                        0.21      0  \n",
       "309         123.95                       -0.20      0  \n",
       "\n",
       "[310 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns=['Pelvic Incidence','Pelvic Tilt','Lumbar Lordosis Angle','Sacral Slope',\n",
    "                           'Pelvic Radius','Grade of Spondylolisthesis','Class']\n",
    "dataset=pd.read_csv(\"../data/vertebral_column_data/column_2C.dat\",sep=\" \",\n",
    "                    names=columns)\n",
    "dataset.replace(['AB','NO'],[1,0],inplace=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (b) Pre-Processing and Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # i. Scatterplots of the Independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=sns.PairGrid(dataset,hue='Class')\n",
    "g.map(sns.scatterplot)\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ii. Boxplots for each of the independent variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pelvic Incidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=dataset,y='Pelvic Incidence',x='Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pelvic Tilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=dataset,y='Pelvic Tilt',x='Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lumbar Lordosis Angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=dataset,y='Lumbar Lordosis Angle',x='Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sacral Slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=dataset,y='Sacral Slope',x='Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pelvic Radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=dataset,y='Pelvic Radius',x='Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grade of Spondylolisthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=dataset,y='Grade of Spondylolisthesis',x='Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iii. Partitioning Data Set into Training and Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal=np.where(dataset[\"Class\"]==1)\n",
    "normal=np.where(dataset['Class']==0)\n",
    "training_data=(pd.concat([dataset.loc[normal].reset_index(drop=True)[:70],dataset.loc[abnormal][:140]])).reset_index(drop=True)\n",
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting Training data into X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train=training_data.iloc[:,:-1],training_data.iloc[:,6]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.concat([dataset.loc[normal].reset_index(drop=True)[70:],dataset.loc[abnormal][140:]]).reset_index(drop=True)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting Test data into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test=test_data.iloc[:,:-1],test_data.iloc[:,6]\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (c) Classification using KNN on Vertebral Column Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i. KNN with k=5 and distance metric as Euclidian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_euclidian=KNeighborsClassifier()\n",
    "knn_euclidian.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ii. Finding the most suitable k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted=knn_euclidian.predict(X_test)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Accuracy : \",knn_euclidian.score(X_test,y_test))\n",
    "error=1-(knn_euclidian.score(X_test,y_test))\n",
    "print (\"Error : \",error )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the most suitable value of k from the test error rate for each k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error=[]\n",
    "test_error=[]\n",
    "k_range=range(208,0,-3)\n",
    "for k in k_range:\n",
    "    classifier_euclidian=KNeighborsClassifier(n_neighbors=k)\n",
    "    classifier_euclidian.fit(X_train,y_train)\n",
    "    y_predict_train=classifier_euclidian.predict(X_train)\n",
    "    y_predict_test=classifier_euclidian.predict(X_test)\n",
    "    train_error.append(np.mean(y_predict_train != y_train))\n",
    "    test_error.append(np.mean(y_predict_test != y_test))\n",
    "#     train_error.append(1-(classifier_euclidian.score(X_train,y_train)))\n",
    "#     test_error.append(1-(classifier_euclidian.score(X_test,y_test)))\n",
    "print (\"Training Error :\\n\")\n",
    "print (train_error)\n",
    "print (\"\\nTest Error :\\n\")\n",
    "print ((test_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of train and test errors vs k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(k_range,train_error,label='Train Error')\n",
    "plt.plot(k_range,test_error,label='Test Error')\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Error')\n",
    "# plt.xlim(-1)\n",
    "plt.axis([210,-2,0,0.4])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding optimal k i.e., k* when test error and train error are given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_star=pd.Series(k_range).loc[np.argmin(test_error)]\n",
    "print (\"k* : \",k_star)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the confusion matrix, true positive rate, true negative rate, precision and f1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier=KNeighborsClassifier(n_neighbors=k_star)\n",
    "knn_classifier.fit(X_train,y_train)\n",
    "# print (knn_k_star_classifier.score(X_test,y_test))\n",
    "y_predict=knn_classifier.predict(X_test)\n",
    "error_euclidian=np.mean(y_predict != y_test)\n",
    "print (\"Error : \",np.mean(y_predict != y_test))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_predict)\n",
    "print (\"Confusion Matrix :\")\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision, Accuracy F1 score (Column 'precision' and 'f1-score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True Positive Rate is the Recall for Class 1, can also be calculated by True Positive/(True Positive + False Negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP=cm[0][0], cm[0][1], cm[1][0], cm[1][1]\n",
    "true_positive_rate=TP/(TP+FN)\n",
    "print (\"True Positive rate : \",true_positive_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True Negative Rate is the recall for Class 0, can also be calculated by True Negative/(True Negative + False Positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_negative_rate=TN/(TN+FP)\n",
    "print (\"True Negative rate : \",true_negative_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iii. Finding k* for varying values of N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_range=range(10,211,10)\n",
    "error=[]\n",
    "k_stars=[]\n",
    "for N in N_range:\n",
    "#     print (N)\n",
    "    training_data_N=(pd.concat([dataset.loc[normal].reset_index(drop=True)[:N//3],\n",
    "                             dataset.loc[abnormal][:N-(N//3)]])).reset_index(drop=True)\n",
    "#     print (training_data_N)\n",
    "    X_train_N,y_train_N=training_data_N.iloc[:,:-1],training_data_N.iloc[:,6]\n",
    "\n",
    "    test_error=[]\n",
    "    k_range=range(1,N,5)\n",
    "    for k in k_range:\n",
    "        knn_classifier=KNeighborsClassifier(n_neighbors=k)\n",
    "        knn_classifier.fit(X_train_N,y_train_N)\n",
    "        y_prediction_N=knn_classifier.predict(X_test)\n",
    "        test_error.append(np.mean(y_prediction_N != y_test))\n",
    "    k_star=pd.Series(k_range).loc[np.argmin(test_error)]\n",
    "    k_stars.append(k_star)\n",
    "    knn=KNeighborsClassifier(n_neighbors=k_star)\n",
    "    knn.fit(X_train_N,y_train_N)\n",
    "    y_predict=knn.predict(X_test)\n",
    "#     print(y_predict)\n",
    "    error.append(np.mean(y_predict != y_test))\n",
    "\n",
    "error_N=min(error)\n",
    "k_star=pd.Series(k_stars).loc[np.argmin(error)]\n",
    "N=pd.Series(N_range).loc[np.argmin(error)]\n",
    "print (\"Minimum Error : \", error_N)\n",
    "print (\"k* :\", k_star)\n",
    "print (\"N :\", N)\n",
    "plt.plot(pd.Series(N_range),error) \n",
    "plt.xlabel('N')\n",
    "plt.ylabel('Best Test Error Rate')\n",
    "# print (error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (d) Using other distance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i. A. Performing KNN using Manhattan distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range=range(1,200,5)\n",
    "error=[]\n",
    "for k in k_range:\n",
    "    knn_manhattan=KNeighborsClassifier(n_neighbors=k,p=1)\n",
    "    knn_manhattan.fit(X_train,y_train)\n",
    "    y_predict=knn_manhattan.predict(X_test)\n",
    "    error.append(np.mean(y_predict != y_test))\n",
    "#     error.append(knn_manhattanttan.score(X_test,y_test))\n",
    "k_star=pd.Series(k_range).loc[np.argmin(error)]\n",
    "print (\"k* :\",k_star)\n",
    "# print (error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K values with their corresponding errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d={\"k\":pd.Series(k_range),\"Error\":error}\n",
    "pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k* can be equal to 6,11 or 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of Error vs k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pd.Series(k_range),error)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_manhattan=KNeighborsClassifier(n_neighbors=k_star,p=1)\n",
    "knn_manhattan.fit(X_train,y_train)\n",
    "y_predict=knn_manhattan.predict(X_test)\n",
    "error_manhattan=np.mean(y_predict != y_test)\n",
    "print (\"Error : \", error_manhattan)\n",
    "confusion_matrix(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i. B. Performing KNN with Minkowski Distance and log10(p) values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the Best log10(p) for k*-manhattan varying p to get the lowest error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_p_values=[]\n",
    "p_values=[]\n",
    "error_log=[]\n",
    "log_p=0.1\n",
    "while (log_p<=1):\n",
    "    log_p_values.append(log_p)\n",
    "    p_value=10**log_p\n",
    "    p_values.append(p_value)\n",
    "    knn_log=KNeighborsClassifier(n_neighbors=k_star,p=p_value)\n",
    "    knn_log.fit(X_train,y_train)\n",
    "    y_predict=knn_log.predict(X_test)\n",
    "    error_log.append(np.mean(y_predict != y_test))\n",
    "    log_p+=0.1\n",
    "    log_p=np.round(log_p,1)\n",
    "best_log_p=pd.Series(log_p_values).loc[np.argmin(error_log)]\n",
    "error_logp=min(error_log)\n",
    "print (\"Error: \",error_logp)\n",
    "print (\"Best log10(p) value :\",best_log_p)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Log10(p) values against errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(log_p_values,error_log)\n",
    "plt.xlabel(\"log10(p)\")\n",
    "plt.ylabel(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_log=KNeighborsClassifier(n_neighbors=k_star,p=(pd.Series(p_values).loc[best_log_p*10-1]))\n",
    "knn_log.fit(X_train,y_train)\n",
    "y_predict=knn_log.predict(X_test)\n",
    "print (\"Confusion matrix : \")\n",
    "confusion_matrix(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i. C. Performing KNN with Chebyshev Distance with p â†’ âˆž"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range=range(1,200,5)\n",
    "error=[]\n",
    "p_value=float('inf')\n",
    "for k in k_range:\n",
    "    knn_chebyshev=KNeighborsClassifier(n_neighbors=k, p=p_value )\n",
    "    knn_chebyshev.fit(X_train,y_train)\n",
    "    y_predict=knn_chebyshev.predict(X_test)\n",
    "    error.append(np.mean(y_predict != y_test))\n",
    "k_star=pd.Series(k_range).loc[np.argmin(error)]\n",
    "error_chebyshev=min(error)\n",
    "print (\"Error : \",error_chebyshev)\n",
    "print (\"k* :\",k_star)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K values with their corresponding errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d={\"K\":pd.Series(k_range),\"Error\":error}\n",
    "pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pd.Series(k_range),error)\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_chebyshev=KNeighborsClassifier(n_neighbors=k_star, p=p_value )\n",
    "knn_chebyshev.fit(X_train,y_train)\n",
    "y_predict=knn_chebyshev.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ii. Performing KNN with Mahalanobis Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance=np.cov(X_train,rowvar=False)\n",
    "print (\"Covariance matrix :\")\n",
    "pd.DataFrame(covariance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating inverse of covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det=np.linalg.det(covariance)\n",
    "print (\"Det :\",det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if det==0:\n",
    "    inverse=np.linalg.pinv(covariance)\n",
    "else:\n",
    "    inverse=np.linalg.inv(covariance)\n",
    "print (\"Inverse of Covariance matrix :\")\n",
    "pd.DataFrame(inverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating k* and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range=range(1,200,5)\n",
    "error=[]\n",
    "for k in k_range:\n",
    "    knn_mahalanobis=KNeighborsClassifier(n_neighbors=k,metric='mahalanobis',metric_params={'VI': inverse })\n",
    "    knn_mahalanobis.fit(X_train,y_train)\n",
    "    y_predict=knn_mahalanobis.predict(X_test)\n",
    "    error.append(np.mean(y_predict != y_test))\n",
    "k_star=pd.Series(k_range).loc[(np.argmin(error))]\n",
    "error_mahalanobis=min(error)\n",
    "print (\"Error : \", error_mahalanobis)\n",
    "print (\"k* :\", k_star)\n",
    "# error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K values with their corresponding errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d={\"K\":pd.Series(k_range),\"Error\":error}\n",
    "pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pd.Series(k_range),error)\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_mahalanobis=KNeighborsClassifier(n_neighbors=k_star,metric='mahalanobis',metric_params={'VI': inverse })\n",
    "knn_mahalanobis.fit(X_train,y_train)\n",
    "y_predict=knn_mahalanobis.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (e) Performing Weighted KNN using different distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using Euclidian distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range=range(1,200,5)\n",
    "error=[]\n",
    "for k in k_range:\n",
    "    knn_weighted_euclidian=KNeighborsClassifier(n_neighbors=k,weights='distance')\n",
    "    knn_weighted_euclidian.fit(X_train,y_train)\n",
    "    y_predict=knn_weighted_euclidian.predict(X_test)\n",
    "    error.append(np.mean(y_predict != y_test))\n",
    "k_star=pd.Series(k_range).loc[(np.argmin(error))]\n",
    "error_euclidian_w=min(error)\n",
    "print (\"Error : \",error_euclidian_w)\n",
    "print (\"k* : \",k_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using Manhattan distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error=[]\n",
    "for k in k_range:\n",
    "    knn_weighted_manhattan=KNeighborsClassifier(n_neighbors=k,metric='manhattan',weights='distance')\n",
    "    knn_weighted_manhattan.fit(X_train,y_train)\n",
    "    y_predict=knn_weighted_manhattan.predict(X_test)\n",
    "    error.append(np.mean(y_predict != y_test))\n",
    "k_star=pd.Series(k_range).loc[(np.argmin(error))]\n",
    "error_manhattan_w=min(error)\n",
    "print (\"Error : \", error_manhattan_w)\n",
    "print (\"k* : \",k_star)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using Chebyshev distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error=[]\n",
    "for k in k_range:\n",
    "    knn_weighted_chebyshev=KNeighborsClassifier(n_neighbors=k,metric='chebyshev',weights='distance')\n",
    "    knn_weighted_chebyshev.fit(X_train,y_train)\n",
    "    y_predict=knn_weighted_chebyshev.predict(X_test)\n",
    "    error.append(np.mean(y_predict != y_test))\n",
    "k_star=pd.Series(k_range).loc[(np.argmin(error))]\n",
    "error_chebyshev_w=min(error)\n",
    "print (\"Error : \",error_chebyshev_w)\n",
    "print (\"k* : \",k_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (e) Lowest training error rate calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Best training error rate for data is achieved for Euclidian distance with error : \",min(train_error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
